{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eefbb90-ad5e-4955-a7fe-ee175bb3e4db",
   "metadata": {},
   "source": [
    "# NLP Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa44165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='3'\n",
    "import tensorflow as tf\n",
    "from helper_functions import importTensorflow\n",
    "importTensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc343f9-dbe9-41db-899d-1b6fe5277843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121e9bfa-5342-4f38-83c8-7f6d19adc511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa189bc0-47e0-4160-804e-a9c81d4feb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle train data\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f5506a-330f-4a3c-b883-4189fa04ce7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b57168-7710-451f-af27-62483f2cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                           train_df_shuffled.target.to_numpy(),\n",
    "                                                                           test_size=0.1,\n",
    "                                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14151325-77ae-4044-8135-510f30ec7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization\n",
    "#default\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=None,\n",
    "                                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                                    split='whitespace',\n",
    "                                                    ngrams=None,\n",
    "                                                    output_mode='int',\n",
    "                                                    output_sequence_length=None,\n",
    "                                                    pad_to_max_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ddea415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ab87ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[1663,   74,   62,   22,   12,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_vocab_length,\n",
    "                                                    output_mode='int',\n",
    "                                                    output_sequence_length=max_length)\n",
    "#fit the text vectorizer\n",
    "text_vectorizer.adapt(train_sentences)\n",
    "text_vectorizer([\"Hi there, how are you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c274de32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x7f0b9d57b790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding\n",
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
    "                                      output_dim=128,\n",
    "                                      input_length=max_length)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561f86e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float16, numpy=\n",
       "array([[[ 4.3884e-02,  3.0155e-03, -7.4883e-03, ..., -2.1255e-02,\n",
       "          4.4800e-02,  1.2260e-02],\n",
       "        [ 5.8830e-05,  8.0185e-03,  2.5528e-02, ...,  4.2877e-02,\n",
       "         -2.9785e-02,  1.4481e-02],\n",
       "        [ 1.9760e-03, -2.9144e-02, -1.2077e-02, ...,  3.4729e-02,\n",
       "         -3.2043e-02, -1.9592e-02],\n",
       "        ...,\n",
       "        [-3.3081e-02,  2.3666e-02,  2.8915e-02, ...,  3.9276e-02,\n",
       "         -2.4918e-02,  1.3336e-02],\n",
       "        [-3.3081e-02,  2.3666e-02,  2.8915e-02, ...,  3.9276e-02,\n",
       "         -2.4918e-02,  1.3336e-02],\n",
       "        [-3.3081e-02,  2.3666e-02,  2.8915e-02, ...,  3.9276e-02,\n",
       "         -2.4918e-02,  1.3336e-02]]], dtype=float16)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(text_vectorizer([\"Hi there, how are you\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4676d978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(train_sentences, train_labels)\n",
    "\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "\n",
    "from helper_functions import calculate_results\n",
    "calculate_results(val_labels, baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de187593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/215 [..............................] - ETA: 6:52 - loss: 0.6929 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1703410303.801683  140566 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 8s 26ms/step - loss: 0.6124 - accuracy: 0.6941 - val_loss: 0.5381 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.4424 - accuracy: 0.8162 - val_loss: 0.4684 - val_accuracy: 0.7822\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 0.3481 - accuracy: 0.8584 - val_loss: 0.4571 - val_accuracy: 0.7940\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2853 - accuracy: 0.8901 - val_loss: 0.4708 - val_accuracy: 0.7940\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.2382 - accuracy: 0.9118 - val_loss: 0.4773 - val_accuracy: 0.7822\n",
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.21522309711287,\n",
       " 'precision': 0.7853104900348995,\n",
       " 'recall': 0.7821522309711286,\n",
       " 'f1': 0.7796592181651525}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1 dense model\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "history_1 = model_1.fit(train_sentences, train_labels,\n",
    "                        validation_data = (val_sentences, val_labels),\n",
    "                        epochs=5)\n",
    "\n",
    "model_1_preds = tf.squeeze(tf.round(model_1.predict(val_sentences)))\n",
    "calculate_results(val_labels, model_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a2f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 39ms/step - loss: 0.2281 - accuracy: 0.9200 - val_loss: 0.5390 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1566 - accuracy: 0.9419 - val_loss: 0.6545 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1285 - accuracy: 0.9520 - val_loss: 0.6846 - val_accuracy: 0.7808\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1038 - accuracy: 0.9580 - val_loss: 0.9048 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0817 - accuracy: 0.9667 - val_loss: 0.8629 - val_accuracy: 0.7730\n",
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.29658792650919,\n",
       " 'precision': 0.7747736761679446,\n",
       " 'recall': 0.7729658792650919,\n",
       " 'f1': 0.7708425630155245}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model2 - LSTM\n",
    "inputs2 = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs2)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.LSTM(64, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(64)(x)\n",
    "# x = tf.keras.layers.Dense(64, activation=tf.keras.activations.relu)(x)\n",
    "outputs2 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_2 = tf.keras.Model(inputs2, outputs2)\n",
    "model_2.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "history_2 = model_2.fit(train_sentences, train_labels,\n",
    "                        epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels))\n",
    "model_2_preds = model_2.predict(val_sentences)\n",
    "calculate_results(val_labels, tf.squeeze(tf.round(model_2_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8ab4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 40ms/step - loss: 0.1494 - accuracy: 0.9454 - val_loss: 0.7316 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.6558 - val_accuracy: 0.7703\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0689 - accuracy: 0.9720 - val_loss: 1.1077 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0559 - accuracy: 0.9752 - val_loss: 0.9254 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0546 - accuracy: 0.9759 - val_loss: 1.0369 - val_accuracy: 0.7782\n",
      "24/24 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7894499714481796,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7729173197612593}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model3 - GRU\n",
    "inputs3 = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs3)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.GRU(64, return_sequences=True)(x)\n",
    "x = tf.keras.layers.GRU(64)(x)\n",
    "outputs3 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_3 = tf.keras.Model(inputs3, outputs3)\n",
    "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "history_3 = model_3.fit(train_sentences, train_labels,\n",
    "                        epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels))\n",
    "mdoel_3_preds = model_3.predict(val_sentences)\n",
    "calculate_results(val_labels, tf.squeeze(tf.round(mdoel_3_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5ef3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 15s 49ms/step - loss: 0.1024 - accuracy: 0.9686 - val_loss: 0.9717 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.0530 - accuracy: 0.9762 - val_loss: 1.0933 - val_accuracy: 0.7651\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0492 - accuracy: 0.9783 - val_loss: 1.2444 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0478 - accuracy: 0.9764 - val_loss: 1.3840 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0418 - accuracy: 0.9799 - val_loss: 1.6109 - val_accuracy: 0.7664\n",
      "24/24 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.64041994750657,\n",
       " 'precision': 0.7674517658976838,\n",
       " 'recall': 0.7664041994750657,\n",
       " 'f1': 0.7645419362124183}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model4 - Bidirectional\n",
    "inputs4 = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs4)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(x)\n",
    "outputs4 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_4 = tf.keras.Model(inputs4, outputs4)\n",
    "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "history_4 = model_4.fit(train_sentences, train_labels,\n",
    "                        epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels))\n",
    "model_4_preds = model_4.predict(val_sentences)\n",
    "calculate_results(val_labels, tf.squeeze(tf.round(model_4_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb73264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 37ms/step - loss: 0.1148 - accuracy: 0.9626 - val_loss: 0.9225 - val_accuracy: 0.7743\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0699 - accuracy: 0.9743 - val_loss: 1.0034 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.0587 - accuracy: 0.9778 - val_loss: 1.0827 - val_accuracy: 0.7769\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.0530 - accuracy: 0.9775 - val_loss: 1.1535 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.0491 - accuracy: 0.9781 - val_loss: 1.2118 - val_accuracy: 0.7703\n",
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7715893693867238,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7684486602580174}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model5 - 1D CNN\n",
    "inputs5 = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs5)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Conv1D(filters=64,\n",
    "                           kernel_size=5,\n",
    "                           padding='same',\n",
    "                           activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
    "outputs5 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_5 = tf.keras.Model(inputs5, outputs5)\n",
    "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "history_5 = model_5.fit(train_sentences, train_labels,\n",
    "                        epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels))\n",
    "model_5_preds = model_5.predict(val_sentences)\n",
    "calculate_results(val_labels, tf.squeeze(tf.round(model_5_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fded77f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 28ms/step - loss: 0.5090 - accuracy: 0.7815 - val_loss: 0.4482 - val_accuracy: 0.8045\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.4137 - accuracy: 0.8183 - val_loss: 0.4397 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.3998 - accuracy: 0.8229 - val_loss: 0.4362 - val_accuracy: 0.8071\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.3923 - accuracy: 0.8273 - val_loss: 0.4282 - val_accuracy: 0.8136\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.3860 - accuracy: 0.8326 - val_loss: 0.4258 - val_accuracy: 0.8189\n",
      "24/24 [==============================] - 1s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.88976377952756,\n",
       " 'precision': 0.8203089036947304,\n",
       " 'recall': 0.8188976377952756,\n",
       " 'f1': 0.8177314483416845}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer learning\n",
    "#model6 - trainsfer learning - USE - Universal sentence encoder\n",
    "import tensorflow_hub as hub\n",
    "embed1 = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "sentence_encoder_layer = hub.KerasLayer(embed1,\n",
    "                                       input_shape=[],\n",
    "                                       dtype=tf.string,\n",
    "                                       trainable=False)\n",
    "model_6 = tf.keras.models.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    tf.keras.layers.Dense(64, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1, activation = tf.keras.activations.sigmoid)\n",
    "])\n",
    "model_6.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "history_6 = model_6.fit(train_sentences, train_labels,\n",
    "                       epochs=5,\n",
    "                       validation_data=(val_sentences, val_labels))\n",
    "model_6_preds=model_6.predict(val_sentences)\n",
    "calculate_results(val_labels, tf.squeeze(tf.round(model_6_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41321e74-2d41-4279-ba62-1bf76bf4a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 75ms/step - loss: 0.6798 - accuracy: 0.6336 - val_loss: 0.6550 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 48ms/step - loss: 0.6160 - accuracy: 0.8058 - val_loss: 0.6013 - val_accuracy: 0.7625\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 49ms/step - loss: 0.5442 - accuracy: 0.8161 - val_loss: 0.5443 - val_accuracy: 0.7664\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 48ms/step - loss: 0.4809 - accuracy: 0.8248 - val_loss: 0.5116 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 47ms/step - loss: 0.4350 - accuracy: 0.8336 - val_loss: 0.4907 - val_accuracy: 0.7756\n",
      "24/24 [==============================] - 1s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.55905511811024,\n",
       " 'precision': 0.7759863909628747,\n",
       " 'recall': 0.7755905511811023,\n",
       " 'f1': 0.7743062301518678}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model7 - 10%data\n",
    "# train_df_10_percent = train_df_shuffled[[\"text\",\"target\"]].sample(frac=0.1, random_state=42) - data leakage\n",
    "train_sentences_10_percent = train_sentences[:int(0.1*len(train_sentences))]\n",
    "train_labels_10_percent = train_labels[:int(0.1*len(train_labels))]\n",
    "\n",
    "model_7 = tf.keras.models.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    tf.keras.layers.Dense(64, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1, activation = tf.keras.activations.sigmoid)\n",
    "])\n",
    "model_7.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "history_7 = model_7.fit(train_sentences_10_percent, train_labels_10_percent,\n",
    "                       epochs=5,\n",
    "                       validation_data=(val_sentences, val_labels))\n",
    "model_7_preds=model_7.predict(val_sentences)\n",
    "calculate_results(val_labels, tf.squeeze(tf.round(model_7_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337430b-c663-40de-bc17-bb6622e6bc36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
